{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "#!{sys.executable} -m pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['deaths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'], format = '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fips'] = df['fips'].fillna(0)\n",
    "df['fips'] = df['fips'].astype(int)\n",
    "df['fips'] = df['fips'].astype(str)\n",
    "df['fips'] = df['fips'].str.zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign New York to a unique FIPS\n",
    "df.loc[df['county'] == 'New York City','fips'] = '36999'\n",
    "\n",
    "#Assign unknown counties to a generic FIPS code for state\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Alabama'),'fips'] = '01000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Alaska'),'fips'] = '02000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Arizona'),'fips'] = '04000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Arkansas'),'fips'] = '05000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'California'),'fips'] = '06000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Colorado'),'fips'] = '08000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Connecticut'),'fips'] = '09000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Delaware'),'fips'] = '10000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Florida'),'fips'] = '12000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Georgia'),'fips'] = '13000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Hawaii'),'fips'] = '15000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Idaho'),'fips'] = '16000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Illinois'),'fips'] = '17000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Indiana'),'fips'] = '18000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Iowa'),'fips'] = '19000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Kansas'),'fips'] = '20000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Kentucky'),'fips'] = '21000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Louisiana'),'fips'] = '22000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Maine'),'fips'] = '23000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Maryland'),'fips'] = '24000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Massachusetts'),'fips'] = '25000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Michigan'),'fips'] = '26000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Minnesota'),'fips'] = '27000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Mississippi'),'fips'] = '28000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Missouri'),'fips'] = '29000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Montana'),'fips'] = '30000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Nebraska'),'fips'] = '31000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Nevada'),'fips'] = '32000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'New Hampshire'),'fips'] = '33000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'New Jersey'),'fips'] = '34000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'New Mexico'),'fips'] = '35000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'New York'),'fips'] = '36000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'North Carolina'),'fips'] = '37000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'North Dakota'),'fips'] = '38000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Ohio'),'fips'] = '39000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Oklahoma'),'fips'] = '40000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Oregon'),'fips'] = '41000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Pennsylvania'),'fips'] = '42000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Rhode Island'),'fips'] = '44000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'South Carolina'),'fips'] = '45000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'South Dakota'),'fips'] = '46000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Tennessee'),'fips'] = '47000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Texas'),'fips'] = '48000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Utah'),'fips'] = '49000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Vermont'),'fips'] = '50000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Virginia'),'fips'] = '51000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Washington'),'fips'] = '53000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'West Virginia'),'fips'] = '54000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Wisconsin'),'fips'] = '55000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Wyoming'),'fips'] = '56000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'American Samoa'),'fips'] = '60000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Guam'),'fips'] = '66000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Northern Mariana Islands'),'fips'] = '69000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Puerto Rico'),'fips'] = '72000'\n",
    "df.loc[(df['county'] == 'Unknown') & (df['state'] == 'Virgin Islands'),'fips'] = '78000'\n",
    "\n",
    "#Assign cities in Missouri based on the county the mostly reside in.\n",
    "df.loc[(df['county'] == 'Joplin') & (df['state'] == 'Missouri'),'fips'] = '29998'\n",
    "df.loc[(df['county'] == 'Kansas City') & (df['state'] == 'Missouri'),'fips'] = '29999'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left = df.copy()\n",
    "df_left['date'] = df_left['date'] + pd.Timedelta(days = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = df.merge(df_left[['date', 'fips', 'cases']], on = ['date', 'fips'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff['cases_y'] = df_diff['cases_y'].fillna(0)\n",
    "df_diff['cases'] = df_diff['cases_x'] - df_diff['cases_y']\n",
    "df_diff = df_diff.drop(columns = ['cases_x', 'cases_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Purpose is to test reasonability of model based on past surges.\n",
    "#We only expected to see a Delta Surge in June for specific regions, like Springfield Missouri.\n",
    "#Delta surge will be much more widespread in July\n",
    "#If our model predicts this behavior, then the results are reasonable.\n",
    "df_diff = df_diff.loc[df_diff['date'] <= pd.to_datetime('2021-06-01', format = '%Y-%m-%d')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data field documentation: \n",
    "# https://svi.cdc.gov/Documents/Data/2016_SVI_Data/SVI2016Documentation.pdf\n",
    "svi = pd.read_csv('https://svi.cdc.gov/Documents/Data/2018_SVI_Data/CSV/SVI2018_US_COUNTY.csv')\n",
    "#Convert to lowercase for better handling when casting CSR matrix\n",
    "svi.columns = svi.columns.str.lower()\n",
    "#Pad leading zeros for FIPS codes\n",
    "svi['fips'] = svi['fips'].astype(int)\n",
    "svi['fips'] = svi['fips'].astype(str)\n",
    "svi['fips'] = svi['fips'].str.zfill(5)\n",
    "#Only use population for now, plan to add more fields from SVI data later\n",
    "svi = svi[['fips', 'e_totpop']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fips codes for New York City Boroughs\n",
    "svi_nyc = svi.loc[svi['fips'].isin(['36085', '36061', '36047', '36081', '36005'])]\n",
    "svi_nyc = svi_nyc.assign(fips = '36999')\n",
    "svi_nyc = svi_nyc.groupby(['fips'], as_index = False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append original data with aggregated NYC data\n",
    "svi = svi.loc[~svi['fips'].isin(['36085', '36061', '36047', '36081', '36005'])]\n",
    "svi = svi.append(svi_nyc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_denom = pd.DataFrame()\n",
    "for x in df_diff['date'].unique():\n",
    "    df_diff_temp = df_diff.loc[df_diff['date'] <= x]\n",
    "    \n",
    "    sorted_val = df_diff_temp.loc[df_diff_temp['cases'] > 0].sort_values(by='date')\n",
    "    recent_result_cases = sorted_val.drop_duplicates('fips', keep='last')\n",
    "\n",
    "    df_diff_temp = df_diff_temp.loc[df_diff_temp['date'] == x]\n",
    "\n",
    "    df_cases_target = df_diff_temp.merge(recent_result_cases[['date', 'fips', 'cases']], on = ['fips'], how = 'left')\n",
    "    df_cases_target['days_since_gt0'] = df_cases_target['date_x'] - df_cases_target['date_y']\n",
    "    df_cases_target.rename(columns={'date_x':'date', 'cases_y':'recent_cases_gt0'}, inplace=True)\n",
    "    df_cases_target = df_cases_target.drop(columns = ['date_y', 'cases_x'])\n",
    "    df_target_denom = df_target_denom.append(df_cases_target)\n",
    "df_target_denom = df_target_denom.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases_lag = \\\n",
    "    df_diff.merge(df_target_denom[['date', 'fips', 'recent_cases_gt0', 'days_since_gt0']], on = ['date', 'fips'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add day_of_week field\n",
    "df_cases_lag['day_of_week']=df_cases_lag['date'].dt.dayofweek\n",
    "#convert day_of_week to Int\n",
    "df_cases_lag['day_of_week'] =df_cases_lag['day_of_week'].astype(int)\n",
    "#rename day_of_week field \n",
    "days = {0:'0_Mon',1:'1_Tues',2:'2_Weds',3:'3_Thurs',4:'4_Fri',5:'5_Sat',6:'6_Sun'}\n",
    "df_cases_lag['day_of_week'] = df_cases_lag['day_of_week'].apply(lambda x: days[x])\n",
    "df_cases_lag['month']=pd.DatetimeIndex(df_cases_lag['date']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left = df_cases_lag.copy()\n",
    "for i in range(1, 31):\n",
    "    df_left['date'] = df_left['date'] - pd.Timedelta(days = -1)\n",
    "    df_cases_lag = df_cases_lag.merge(df_left[['date', 'fips', 'cases']], on = ['date', 'fips'], how = 'inner')\n",
    "    df_cases_lag.rename(columns={'cases_y':'cases' + str(i).zfill(2)}, inplace=True)\n",
    "    df_cases_lag.rename(columns={'cases_x':'cases'}, inplace=True)\n",
    "df_cases_lag.rename(columns={'cases':'cases00'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gordo\\AppData\\Local\\Temp/ipykernel_24724/3537972354.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cases_lag['cases'  + str(i).zfill(2) + '_deriv2_norm'] = \\\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    df_cases_lag['cases'  + str(i).zfill(2) + '_norm'] = df_cases_lag['cases' + str(i).zfill(2)] / df_cases_lag['recent_cases_gt0']\n",
    "for i in range(29):\n",
    "    df_cases_lag['cases'  + str(i).zfill(2) + '_deriv1_norm'] = \\\n",
    "        df_cases_lag['cases'  + str(i).zfill(2) + '_norm'] \\\n",
    "            - df_cases_lag['cases'  + str(i + 1).zfill(2) + '_norm']\n",
    "for i in range(28):\n",
    "    df_cases_lag['cases'  + str(i).zfill(2) + '_deriv2_norm'] = \\\n",
    "        df_cases_lag['cases'  + str(i).zfill(2) + '_deriv1_norm'] \\\n",
    "            - df_cases_lag['cases'  + str(i + 1).zfill(2) + '_deriv1_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff_state = df_diff.copy()\n",
    "df_diff_state['fips_st'] = df_diff_state['fips'].str.slice(0,2) + '000'\n",
    "df_diff_state = df_diff_state.groupby(['date', 'fips_st'], as_index = False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_denom_state = pd.DataFrame()\n",
    "for x in df_diff_state['date'].unique():\n",
    "    df_diff_temp = df_diff_state.loc[df_diff_state['date'] <= x]\n",
    "    \n",
    "    sorted_val = df_diff_temp.loc[df_diff_temp['cases'] > 0].sort_values(by='date')\n",
    "    recent_result_cases = sorted_val.drop_duplicates('fips_st', keep='last')\n",
    "\n",
    "    df_diff_temp = df_diff_temp.loc[df_diff_temp['date'] == x]\n",
    "\n",
    "    df_cases_target = df_diff_temp.merge(recent_result_cases[['date', 'fips_st', 'cases']], on = ['fips_st'], how = 'left')\n",
    "    df_cases_target['days_since_gt0'] = df_cases_target['date_x'] - df_cases_target['date_y']\n",
    "    df_cases_target.rename(columns={'date_x':'date', 'cases_y':'recent_cases_gt0'}, inplace=True)\n",
    "    df_cases_target = df_cases_target.drop(columns = ['date_y', 'cases_x'])\n",
    "    df_target_denom_state = df_target_denom_state.append(df_cases_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases_lag_state = \\\n",
    "    df_diff_state.merge(df_target_denom_state[['date', 'fips_st', 'recent_cases_gt0', 'days_since_gt0']], on = ['date', 'fips_st'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left_state = df_cases_lag_state.copy()\n",
    "for i in range(1, 31):\n",
    "    df_left_state['date'] = df_left_state['date'] - pd.Timedelta(days = -1)\n",
    "    df_cases_lag_state = df_cases_lag_state.merge(df_left_state[['date', 'fips_st', 'cases']], on = ['date', 'fips_st'], how = 'inner')\n",
    "    df_cases_lag_state.rename(columns={'cases_y':'cases' + str(i).zfill(2)}, inplace=True)\n",
    "    df_cases_lag_state.rename(columns={'cases_x':'cases'}, inplace=True)\n",
    "df_cases_lag_state.rename(columns={'cases':'cases00'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gordo\\AppData\\Local\\Temp/ipykernel_24724/1049967788.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cases_lag_state['cases'  + str(i).zfill(2) + '_deriv2_norm'] = \\\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    df_cases_lag_state['cases'  + str(i).zfill(2) + '_norm'] = df_cases_lag_state['cases' + str(i).zfill(2)] / df_cases_lag_state['recent_cases_gt0']\n",
    "for i in range(29):\n",
    "    df_cases_lag_state['cases'  + str(i).zfill(2) + '_deriv1_norm'] = \\\n",
    "        df_cases_lag_state['cases'  + str(i).zfill(2) + '_norm'] \\\n",
    "            - df_cases_lag_state['cases'  + str(i + 1).zfill(2) + '_norm']\n",
    "for i in range(28):\n",
    "    df_cases_lag_state['cases'  + str(i).zfill(2) + '_deriv2_norm'] = \\\n",
    "        df_cases_lag_state['cases'  + str(i).zfill(2) + '_deriv1_norm'] \\\n",
    "            - df_cases_lag_state['cases'  + str(i + 1).zfill(2) + '_deriv1_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff_nation = df_diff.copy()\n",
    "df_diff_nation = df_diff_nation.groupby(['date'], as_index = False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_denom_nation = pd.DataFrame()\n",
    "for x in df_diff_nation['date'].unique():\n",
    "    df_diff_temp = df_diff_nation.loc[df_diff_nation['date'] <= x]\n",
    "    \n",
    "    sorted_val = df_diff_temp.loc[df_diff_temp['cases'] > 0].sort_values(by='date')\n",
    "    recent_result_cases = sorted_val.tail(1)\n",
    "    recent_result_cases = recent_result_cases.assign(days_since_gt0 = x - recent_result_cases['date'], date = x)\n",
    "    \n",
    "    recent_result_cases.rename(columns={'cases':'recent_cases_gt0'}, inplace=True)\n",
    "    df_target_denom_nation = df_target_denom_nation.append(recent_result_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases_lag_nation = \\\n",
    "    df_diff_nation.merge(df_target_denom_nation[['date', 'recent_cases_gt0', 'days_since_gt0']], on = ['date'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left_nation = df_cases_lag_nation.copy()\n",
    "for i in range(1, 31):\n",
    "    df_left_nation['date'] = df_left_nation['date'] - pd.Timedelta(days = -1)\n",
    "    df_cases_lag_nation = df_cases_lag_nation.merge(df_left_nation[['date', 'cases']], on = ['date', ], how = 'inner')\n",
    "    df_cases_lag_nation.rename(columns={'cases_y':'cases' + str(i).zfill(2)}, inplace=True)\n",
    "    df_cases_lag_nation.rename(columns={'cases_x':'cases'}, inplace=True)\n",
    "df_cases_lag_nation.rename(columns={'cases':'cases00'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gordo\\AppData\\Local\\Temp/ipykernel_24724/4077784464.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_cases_lag_nation['cases'  + str(i).zfill(2) + '_deriv2_norm'] = \\\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    df_cases_lag_nation['cases'  + str(i).zfill(2) + '_norm'] = df_cases_lag_nation['cases' + str(i).zfill(2)] / df_cases_lag_state['recent_cases_gt0']\n",
    "for i in range(29):\n",
    "    df_cases_lag_nation['cases'  + str(i).zfill(2) + '_deriv1_norm'] = \\\n",
    "        df_cases_lag_nation['cases'  + str(i).zfill(2) + '_norm'] \\\n",
    "            - df_cases_lag_nation['cases' + str(i + 1).zfill(2) + '_norm']\n",
    "for i in range(28):\n",
    "    df_cases_lag_nation['cases'  + str(i).zfill(2) + '_deriv2_norm'] = \\\n",
    "        df_cases_lag_nation['cases'  + str(i).zfill(2) + '_deriv1_norm'] \\\n",
    "            - df_cases_lag_nation['cases'  + str(i + 1).zfill(2) + '_deriv1_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>fips</th>\n",
       "      <th>cases00</th>\n",
       "      <th>recent_cases_gt0</th>\n",
       "      <th>days_since_gt0</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>cases01</th>\n",
       "      <th>...</th>\n",
       "      <th>cases18_deriv2_norm</th>\n",
       "      <th>cases19_deriv2_norm</th>\n",
       "      <th>cases20_deriv2_norm</th>\n",
       "      <th>cases21_deriv2_norm</th>\n",
       "      <th>cases22_deriv2_norm</th>\n",
       "      <th>cases23_deriv2_norm</th>\n",
       "      <th>cases24_deriv2_norm</th>\n",
       "      <th>cases25_deriv2_norm</th>\n",
       "      <th>cases26_deriv2_norm</th>\n",
       "      <th>cases27_deriv2_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1278782</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>Sweetwater</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56037</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0 days</td>\n",
       "      <td>1_Tues</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042553</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.361702</td>\n",
       "      <td>-0.744681</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.191489</td>\n",
       "      <td>-0.127660</td>\n",
       "      <td>-0.106383</td>\n",
       "      <td>-0.085106</td>\n",
       "      <td>0.468085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278783</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>Teton</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0 days</td>\n",
       "      <td>1_Tues</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>-17.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278784</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>Uinta</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56041</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0 days</td>\n",
       "      <td>1_Tues</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>-3.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.666667</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278785</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>Washakie</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56043</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0 days</td>\n",
       "      <td>1_Tues</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>-3.333333</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278786</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>Weston</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>56045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0 days</td>\n",
       "      <td>1_Tues</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date      county    state   fips  cases00  recent_cases_gt0  \\\n",
       "1278782 2021-06-01  Sweetwater  Wyoming  56037     47.0              47.0   \n",
       "1278783 2021-06-01       Teton  Wyoming  56039      1.0               1.0   \n",
       "1278784 2021-06-01       Uinta  Wyoming  56041      6.0               6.0   \n",
       "1278785 2021-06-01    Washakie  Wyoming  56043      3.0               3.0   \n",
       "1278786 2021-06-01      Weston  Wyoming  56045      1.0               1.0   \n",
       "\n",
       "        days_since_gt0 day_of_week  month  cases01  ...  cases18_deriv2_norm  \\\n",
       "1278782         0 days      1_Tues      6      0.0  ...            -0.042553   \n",
       "1278783         0 days      1_Tues      6      0.0  ...             1.000000   \n",
       "1278784         0 days      1_Tues      6      0.0  ...            -0.333333   \n",
       "1278785         0 days      1_Tues      6      0.0  ...            -2.333333   \n",
       "1278786         0 days      1_Tues      6      0.0  ...             0.000000   \n",
       "\n",
       "         cases19_deriv2_norm  cases20_deriv2_norm  cases21_deriv2_norm  \\\n",
       "1278782             0.021277             0.361702            -0.744681   \n",
       "1278783             1.000000             0.000000            -5.000000   \n",
       "1278784             0.333333             1.333333            -3.500000   \n",
       "1278785             1.000000             0.000000            -0.333333   \n",
       "1278786             0.000000             0.000000             0.000000   \n",
       "\n",
       "         cases22_deriv2_norm  cases23_deriv2_norm  cases24_deriv2_norm  \\\n",
       "1278782             0.446809             0.191489            -0.127660   \n",
       "1278783             4.000000            -2.000000            13.000000   \n",
       "1278784             2.000000             1.000000            -1.666667   \n",
       "1278785             0.333333             0.000000             0.000000   \n",
       "1278786             0.000000             0.000000             0.000000   \n",
       "\n",
       "         cases25_deriv2_norm  cases26_deriv2_norm  cases27_deriv2_norm  \n",
       "1278782            -0.106383            -0.085106             0.468085  \n",
       "1278783           -17.000000             5.000000             6.000000  \n",
       "1278784             1.166667             0.166667            -0.166667  \n",
       "1278785             1.666667            -3.333333             2.666667  \n",
       "1278786             0.000000             0.000000             1.000000  \n",
       "\n",
       "[5 rows x 126 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cases_lag.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next Steps\n",
    "#(0) Make 28 target variables, one for each day.\n",
    "#(1) Make a 28-day forecast, one for 2021-06-01, one for 2021-07-01.\n",
    "#(2) Predict completion, and then multiply by these values.\n",
    "#(3) See if a surge exists for June in Springfield Missouri\n",
    "#(4) See if a surge exists for July` for rest of United States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left = df_diff.copy()\n",
    "df_left['date'] = df_left['date'] - pd.Timedelta(days = 1)\n",
    "df_lookforward_01 = df_diff.merge(df_left[['date', 'fips', 'cases']], on = ['date', 'fips'], how = 'inner')\n",
    "df_lookforward_01.rename(columns={'cases_y':'cases'}, inplace=True)\n",
    "df_lookforward_01 = df_lookforward_01.drop(columns = ['cases_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases_completion = \\\n",
    "    df_target_denom.merge(df_lookforward_01[['date', 'fips', 'cases']], on = ['date', 'fips'], how = 'inner')\n",
    "df_cases_completion['_target'] = df_cases_completion['cases'] / df_cases_completion['recent_cases_gt0']\n",
    "df_cases_completion.loc[(df_cases_completion['_target'] < 0 ),'_target'] = 0\n",
    "#Double log transform\n",
    "df_cases_completion['_target'] = np.log1p(np.log1p(df_cases_completion['_target']))\n",
    "df_cases_completion = \\\n",
    "    df_cases_completion.drop(columns = ['county', 'state', 'recent_cases_gt0', 'days_since_gt0', 'cases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "df_long = pd.DataFrame()\n",
    "for i in range(1,29):\n",
    "    df_left = df_diff.copy()\n",
    "    df_left['date'] = df_left['date'] - pd.Timedelta(days = i)\n",
    "    df_lookforward = df_diff.merge(df_left[['date', 'fips', 'cases']], on = ['date', 'fips'], how = 'inner')\n",
    "    df_lookforward.rename(columns={'cases_y':'cases'}, inplace=True)\n",
    "    df_lookforward = df_lookforward.drop(columns = ['cases_x'])\n",
    "    df_cases_completion = \\\n",
    "        df_target_denom.merge(df_lookforward[['date', 'fips', 'cases']], on = ['date', 'fips'], how = 'inner')\n",
    "    df_cases_completion = df_cases_completion.assign(variable = '_target'+ str(i).zfill(2))\n",
    "    df_cases_completion = \\\n",
    "        df_cases_completion.assign(val = df_cases_completion['cases'] / df_cases_completion['recent_cases_gt0'])\n",
    "    df_cases_completion.loc[df_cases_completion['val'] < 0] = 0\n",
    "    #Double log transform\n",
    "    df_cases_completion['val'] = \\\n",
    "        np.log1p(np.log1p(df_cases_completion['val']))\n",
    "    df_cases_completion = \\\n",
    "        df_cases_completion.drop(columns = ['county', 'state', 'recent_cases_gt0', 'days_since_gt0', 'cases'])\n",
    "    df_long = df_long.append(df_cases_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>fips</th>\n",
       "      <th>variable</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1268872</th>\n",
       "      <td>2021-04-29 00:00:00</td>\n",
       "      <td>36999</td>\n",
       "      <td>_target14</td>\n",
       "      <td>0.387273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272119</th>\n",
       "      <td>2021-04-30 00:00:00</td>\n",
       "      <td>36999</td>\n",
       "      <td>_target14</td>\n",
       "      <td>0.338234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275365</th>\n",
       "      <td>2021-05-01 00:00:00</td>\n",
       "      <td>36999</td>\n",
       "      <td>_target14</td>\n",
       "      <td>0.188241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278611</th>\n",
       "      <td>2021-05-02 00:00:00</td>\n",
       "      <td>36999</td>\n",
       "      <td>_target14</td>\n",
       "      <td>0.440449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281857</th>\n",
       "      <td>2021-05-03 00:00:00</td>\n",
       "      <td>36999</td>\n",
       "      <td>_target14</td>\n",
       "      <td>0.341597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285103</th>\n",
       "      <td>2021-05-04 00:00:00</td>\n",
       "      <td>36999</td>\n",
       "      <td>_target14</td>\n",
       "      <td>0.535735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288349</th>\n",
       "      <td>2021-05-05 00:00:00</td>\n",
       "      <td>36999</td>\n",
       "      <td>_target14</td>\n",
       "      <td>0.267130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291595</th>\n",
       "      <td>2021-05-06 00:00:00</td>\n",
       "      <td>36999</td>\n",
       "      <td>_target14</td>\n",
       "      <td>0.377619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294841</th>\n",
       "      <td>2021-05-07 00:00:00</td>\n",
       "      <td>36999</td>\n",
       "      <td>_target14</td>\n",
       "      <td>0.400928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298087</th>\n",
       "      <td>2021-05-08 00:00:00</td>\n",
       "      <td>36999</td>\n",
       "      <td>_target14</td>\n",
       "      <td>0.302321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301334</th>\n",
       "      <td>2021-05-09 00:00:00</td>\n",
       "      <td>36999</td>\n",
       "      <td>_target14</td>\n",
       "      <td>0.315900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304580</th>\n",
       "      <td>2021-05-10 00:00:00</td>\n",
       "      <td>36999</td>\n",
       "      <td>_target14</td>\n",
       "      <td>0.340685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307826</th>\n",
       "      <td>2021-05-11 00:00:00</td>\n",
       "      <td>36999</td>\n",
       "      <td>_target14</td>\n",
       "      <td>0.511837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311072</th>\n",
       "      <td>2021-05-12 00:00:00</td>\n",
       "      <td>36999</td>\n",
       "      <td>_target14</td>\n",
       "      <td>0.247423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314318</th>\n",
       "      <td>2021-05-13 00:00:00</td>\n",
       "      <td>36999</td>\n",
       "      <td>_target14</td>\n",
       "      <td>0.389380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317564</th>\n",
       "      <td>2021-05-14 00:00:00</td>\n",
       "      <td>36999</td>\n",
       "      <td>_target14</td>\n",
       "      <td>0.338215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320809</th>\n",
       "      <td>2021-05-15 00:00:00</td>\n",
       "      <td>36999</td>\n",
       "      <td>_target14</td>\n",
       "      <td>0.480860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324054</th>\n",
       "      <td>2021-05-16 00:00:00</td>\n",
       "      <td>36999</td>\n",
       "      <td>_target14</td>\n",
       "      <td>0.253859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327299</th>\n",
       "      <td>2021-05-17 00:00:00</td>\n",
       "      <td>36999</td>\n",
       "      <td>_target14</td>\n",
       "      <td>0.294244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330544</th>\n",
       "      <td>2021-05-18 00:00:00</td>\n",
       "      <td>36999</td>\n",
       "      <td>_target14</td>\n",
       "      <td>0.224098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date   fips   variable       val\n",
       "1268872  2021-04-29 00:00:00  36999  _target14  0.387273\n",
       "1272119  2021-04-30 00:00:00  36999  _target14  0.338234\n",
       "1275365  2021-05-01 00:00:00  36999  _target14  0.188241\n",
       "1278611  2021-05-02 00:00:00  36999  _target14  0.440449\n",
       "1281857  2021-05-03 00:00:00  36999  _target14  0.341597\n",
       "1285103  2021-05-04 00:00:00  36999  _target14  0.535735\n",
       "1288349  2021-05-05 00:00:00  36999  _target14  0.267130\n",
       "1291595  2021-05-06 00:00:00  36999  _target14  0.377619\n",
       "1294841  2021-05-07 00:00:00  36999  _target14  0.400928\n",
       "1298087  2021-05-08 00:00:00  36999  _target14  0.302321\n",
       "1301334  2021-05-09 00:00:00  36999  _target14  0.315900\n",
       "1304580  2021-05-10 00:00:00  36999  _target14  0.340685\n",
       "1307826  2021-05-11 00:00:00  36999  _target14  0.511837\n",
       "1311072  2021-05-12 00:00:00  36999  _target14  0.247423\n",
       "1314318  2021-05-13 00:00:00  36999  _target14  0.389380\n",
       "1317564  2021-05-14 00:00:00  36999  _target14  0.338215\n",
       "1320809  2021-05-15 00:00:00  36999  _target14  0.480860\n",
       "1324054  2021-05-16 00:00:00  36999  _target14  0.253859\n",
       "1327299  2021-05-17 00:00:00  36999  _target14  0.294244\n",
       "1330544  2021-05-18 00:00:00  36999  _target14  0.224098"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long.loc[(df_long['fips'] == '36999') & (df_long['variable'] == '_target14')].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4749.90234375\n"
     ]
    }
   ],
   "source": [
    "#Test memory usage\n",
    "import os, psutil\n",
    "process = psutil.Process(os.getpid())\n",
    "print(psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>recent_cases_gt0</th>\n",
       "      <th>days_since_gt0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>2022-03-14</td>\n",
       "      <td>49636.0</td>\n",
       "      <td>0 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>2022-03-15</td>\n",
       "      <td>25738.0</td>\n",
       "      <td>0 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>2022-03-16</td>\n",
       "      <td>39384.0</td>\n",
       "      <td>0 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>2022-03-17</td>\n",
       "      <td>35842.0</td>\n",
       "      <td>0 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>2022-03-18</td>\n",
       "      <td>36267.0</td>\n",
       "      <td>0 days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  recent_cases_gt0 days_since_gt0\n",
       "783 2022-03-14           49636.0         0 days\n",
       "784 2022-03-15           25738.0         0 days\n",
       "785 2022-03-16           39384.0         0 days\n",
       "786 2022-03-17           35842.0         0 days\n",
       "787 2022-03-18           36267.0         0 days"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target_denom_nation.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases_lag.loc[df_cases_lag['fips'] == '36999'].to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2076/74319957.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkeys_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mfull_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'unique_key'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mordered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mvar_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mfull_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mordered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfull_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'unique_key'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeys_c\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfull_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'unique_key'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_c\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'full_df' is not defined"
     ]
    }
   ],
   "source": [
    "#Code Template for Later\n",
    "\n",
    "#keys_c = CategoricalDtype( sorted( full_df['unique_key'].unique()), ordered = True)\n",
    "#var_c = CategoricalDtype( sorted( full_df.variable.unique()), ordered = True)\n",
    "#row = full_df['unique_key'].astype(keys_c).cat.codes\n",
    "#col = full_df['unique_key'].astype(var_c).cat.codes\n",
    "\n",
    "#sparse_matrix = csr_matrix((full_df['val'], (row, col)), shape = keys_c.categories.size, var_c = categories.size)\n",
    "#X = sparse_matrix[0:train_index, 1:]\n",
    "#Y = pd.DataFrame(sparse_matrix[0:train_index, 0:].astype(np.int).todense())\n",
    "#score_X = sparse_matrix[train_index:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>fips</th>\n",
       "      <th>recent_cases_gt0</th>\n",
       "      <th>days_since_gt0</th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "      <th>_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2267295</th>\n",
       "      <td>2022-03-02</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>Texas</td>\n",
       "      <td>48113</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0 days</td>\n",
       "      <td>98.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.611628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270547</th>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>Texas</td>\n",
       "      <td>48113</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0 days</td>\n",
       "      <td>82.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.474985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273801</th>\n",
       "      <td>2022-03-04</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>Texas</td>\n",
       "      <td>48113</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0 days</td>\n",
       "      <td>152.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.717158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2277055</th>\n",
       "      <td>2022-03-05</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>Texas</td>\n",
       "      <td>48113</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0 days</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.100766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2280308</th>\n",
       "      <td>2022-03-06</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>Texas</td>\n",
       "      <td>48113</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0 days</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.213512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  county  state   fips  recent_cases_gt0 days_since_gt0  \\\n",
       "2267295 2022-03-02  Dallas  Texas  48113              74.0         0 days   \n",
       "2270547 2022-03-03  Dallas  Texas  48113              98.0         0 days   \n",
       "2273801 2022-03-04  Dallas  Texas  48113              82.0         0 days   \n",
       "2277055 2022-03-05  Dallas  Texas  48113             152.0         0 days   \n",
       "2280308 2022-03-06  Dallas  Texas  48113              17.0         0 days   \n",
       "\n",
       "         cases  deaths   _target  \n",
       "2267295   98.0     6.0  0.611628  \n",
       "2270547   82.0    22.0  0.474985  \n",
       "2273801  152.0    12.0  0.717158  \n",
       "2277055   17.0     2.0  0.100766  \n",
       "2280308  164.0     0.0  1.213512  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_cases_completion.loc[df_cases_completion['fips'] == '48113'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>fips</th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "      <th>date_shift01</th>\n",
       "      <th>date_shift02</th>\n",
       "      <th>date_shift03</th>\n",
       "      <th>date_shift04</th>\n",
       "      <th>...</th>\n",
       "      <th>date_shift21</th>\n",
       "      <th>date_shift22</th>\n",
       "      <th>date_shift23</th>\n",
       "      <th>date_shift24</th>\n",
       "      <th>date_shift25</th>\n",
       "      <th>date_shift26</th>\n",
       "      <th>date_shift27</th>\n",
       "      <th>date_shift28</th>\n",
       "      <th>date_shift29</th>\n",
       "      <th>date_shift30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, county, state, fips, cases, deaths, date_shift01, date_shift02, date_shift03, date_shift04, date_shift05, date_shift06, date_shift07, date_shift08, date_shift09, date_shift10, date_shift11, date_shift12, date_shift13, date_shift14, date_shift15, date_shift16, date_shift17, date_shift18, date_shift19, date_shift20, date_shift21, date_shift22, date_shift23, date_shift24, date_shift25, date_shift26, date_shift27, date_shift28, date_shift29, date_shift30]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 36 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing for later\n",
    "#for i in range(30):\n",
    "#    df['date_shift' + str(i + 1).zfill(2)] = df['date'] + pd.Timedelta(days = i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need three columns\n",
    "#A key (based on date and fips)\n",
    "#A variable name\n",
    "#A variable value\n",
    "#Target variable will be percent increase"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
